# Suite of functions to parse word lists

def load_period(period): 
    """ load the xml file with the data """
    period_file = period + '.xml'
    data_dir = "/Users/nernst/Documents/papers/current-papers/abram/naming-paper/data/maxdb-tagged/"
    
    import lxml.etree
    doc = lxml.etree.parse(data_dir + period_file)
    topics = doc.findall('Topic')
    #spme test establishing correct number
    return topics
    
def load_wordlists(): 
    """ load the datafile with the wordlists we want to use """
    exp = '../exp2/'
    quality_map = {'portability':[], 'efficiency':[], 'reliability':[], 'functionality':[], 'usability':[], 'maintainability':[]}
    for q in quality_map.keys():
        q_file = open(exp + 'wordlist.' + q)
        for line in q_file:
            quality_map[q].append(line.rstrip())
    return quality_map
    
def create_element_list(topic):
    """Parse each period and create a list of elements and annotations in that topic, 
    to some threshold. arg topic is an ElementTree Element"""
    threshold = -99.0
    annotations = []
    thresh_el = [] # the list of elements 'above' the threshold
    import re
    url = re.compile('http:\/\/.*') # this will parse out (some) urls 
    elements = topic.findall('Elements/Elm') # should use some sort of comprehension here to filter on threshold
    for elm in elements:
        if float(elm.attrib['freq']) > threshold and url.match(elm.attrib['word']) == None:
            thresh_el.append(elm.attrib['word'])
    
    anno = topic.findall('Annotation')
    for a in anno:
        annotations.append(a.attrib['name'])
    return annotations, thresh_el
    
def index_matching_wordlists(thresh_el, annotations, quality_map):
    """"""
    el_results = {}
    anno_results = []
    count = 0
    for quality in quality_map.keys():
        for keyword in quality_map[quality]:
            if keyword in thresh_el:
                count = count + 1 #count of occurences for that quality's keywords
        # assign the count to that quality
        el_results[quality] = count
        count = 0
    matches = [x for x in el_results.keys() if el_results[x] > 0]  # only print matches   
    overlap = False           
    for m in matches:
        if m in annotations or annotations[0] == 'none':
            overlap = True
    if overlap:
        print 'yes'
    else:
        print "no match"

def compare_results():
    """"""
    # Create a list of annotations indexed to period/topic.
# Compare the annotation qualities per period/topic to the list generated by lda.

if __name__ == '__main__':
    maxdb_periods = ["1088563753", "1098931753",   "1119667753",  "1132627753",  "1142995753", 
                    "1091155753",  "1101523753",  "1122259753",  "1135219753",  "1145587753", 
                    "1093747753",  "1104115753",  "1124851753",  "1137811753",  "1148179753", 
                    "1096339753",  "1106707753",  "1130035753",  "1140403753",  "1150771753"]
    # test_period = '1098931753'
    #     topics = load_period(test_period)
    quality_map = load_wordlists()
    for period in maxdb_periods:
        print "Period #" + period
        topics = load_period(period)
        for t in topics:
            annotations, thresh_el = create_element_list(t)
            index_matching_wordlists(thresh_el, annotations, quality_map)

    